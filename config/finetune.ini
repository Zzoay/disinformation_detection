
[data]
batch_size = 32
fold = 5


[model]
hidden_size = 400
dropout = 0.33
num_label = 2


[trainer]
# trainer configuration
seed = 666
cuda = True
epochs = 50

# early stopping( in every 'early_stop' evaluation times)
early_stop = 10

optimizer = 'Adam'
lr = 2e-5

update_every = 4
print_every = 100
eval_every = 200
clip = 5

warmup_step = 1000