
[data]
data_dir = "processed_data/"
batch_size = 8
fold = 5


[model]
hidden_size = 768
dropout = 0.33
num_labels = 2


[trainer]
# trainer configuration
seed = [666, 888, 233, 999, 1000, 6, 100, 200, 1080, 777]
cuda = False
epochs = 20
; epochs = 30

; early stopping( in every 'early_stop' evaluation times)
early_stop = 20

optimizer = 'Adam'
lr = 3e-6

; update_every = 5

print_every = 50
eval_every = 100
clip = 6

; warmup_step = 100

weight_decay = 1e-4